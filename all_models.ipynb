{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human activity detector by smartphone sensor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependancies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data\n",
    "X_train = pd.read_csv(\"Dataset/Train/X_train.txt\", sep = \" \", header = None)\n",
    "y_train = pd.read_csv(\"Dataset/Train/y_train.txt\", sep = \" \", header = None)\n",
    "\n",
    "#Testing data\n",
    "X_test = pd.read_csv(\"Dataset/Test/X_test.txt\", sep = \" \", header = None)\n",
    "y_test = pd.read_csv(\"Dataset/Test/y_test.txt\", sep = \" \", header = None)\n",
    "\n",
    "#activity labels\n",
    "y_labels = pd.read_csv(\"Dataset/activity_labels.txt\", header = None)\n",
    "\n",
    "#feature labels\n",
    "features = pd.read_csv(\"Dataset/features.txt\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043580</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.035054</td>\n",
       "      <td>-0.995381</td>\n",
       "      <td>-0.988366</td>\n",
       "      <td>-0.937382</td>\n",
       "      <td>-0.995007</td>\n",
       "      <td>-0.988816</td>\n",
       "      <td>-0.953325</td>\n",
       "      <td>-0.794796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012236</td>\n",
       "      <td>-0.314848</td>\n",
       "      <td>-0.713308</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841559</td>\n",
       "      <td>0.179913</td>\n",
       "      <td>-0.051718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039480</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>-0.029067</td>\n",
       "      <td>-0.998348</td>\n",
       "      <td>-0.982945</td>\n",
       "      <td>-0.971273</td>\n",
       "      <td>-0.998702</td>\n",
       "      <td>-0.983315</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.802537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202804</td>\n",
       "      <td>-0.603199</td>\n",
       "      <td>-0.860677</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.845092</td>\n",
       "      <td>0.180261</td>\n",
       "      <td>-0.047436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039978</td>\n",
       "      <td>-0.005153</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>-0.995482</td>\n",
       "      <td>-0.977314</td>\n",
       "      <td>-0.984760</td>\n",
       "      <td>-0.996415</td>\n",
       "      <td>-0.975835</td>\n",
       "      <td>-0.985973</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440079</td>\n",
       "      <td>-0.404427</td>\n",
       "      <td>-0.761847</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.849230</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>-0.042271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039785</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.028916</td>\n",
       "      <td>-0.996194</td>\n",
       "      <td>-0.988569</td>\n",
       "      <td>-0.993256</td>\n",
       "      <td>-0.996994</td>\n",
       "      <td>-0.988526</td>\n",
       "      <td>-0.993135</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430891</td>\n",
       "      <td>-0.138373</td>\n",
       "      <td>-0.491604</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848947</td>\n",
       "      <td>0.181907</td>\n",
       "      <td>-0.040826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038758</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.998241</td>\n",
       "      <td>-0.986774</td>\n",
       "      <td>-0.993115</td>\n",
       "      <td>-0.998216</td>\n",
       "      <td>-0.986479</td>\n",
       "      <td>-0.993825</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137735</td>\n",
       "      <td>-0.366214</td>\n",
       "      <td>-0.702490</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.848164</td>\n",
       "      <td>0.185124</td>\n",
       "      <td>-0.037080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.043580 -0.005970 -0.035054 -0.995381 -0.988366 -0.937382 -0.995007   \n",
       "1  0.039480 -0.002131 -0.029067 -0.998348 -0.982945 -0.971273 -0.998702   \n",
       "2  0.039978 -0.005153 -0.022651 -0.995482 -0.977314 -0.984760 -0.996415   \n",
       "3  0.039785 -0.011809 -0.028916 -0.996194 -0.988569 -0.993256 -0.996994   \n",
       "4  0.038758 -0.002289 -0.023863 -0.998241 -0.986774 -0.993115 -0.998216   \n",
       "\n",
       "        7         8         9    ...       551       552       553       554  \\\n",
       "0 -0.988816 -0.953325 -0.794796  ... -0.012236 -0.314848 -0.713308 -0.112754   \n",
       "1 -0.983315 -0.974000 -0.802537  ...  0.202804 -0.603199 -0.860677  0.053477   \n",
       "2 -0.975835 -0.985973 -0.798477  ...  0.440079 -0.404427 -0.761847 -0.118559   \n",
       "3 -0.988526 -0.993135 -0.798477  ...  0.430891 -0.138373 -0.491604 -0.036788   \n",
       "4 -0.986479 -0.993825 -0.801982  ...  0.137735 -0.366214 -0.702490  0.123320   \n",
       "\n",
       "        555       556       557       558       559       560  \n",
       "0  0.030400 -0.464761 -0.018446 -0.841559  0.179913 -0.051718  \n",
       "1 -0.007435 -0.732626  0.703511 -0.845092  0.180261 -0.047436  \n",
       "2  0.177899  0.100699  0.808529 -0.849230  0.180610 -0.042271  \n",
       "3 -0.012892  0.640011 -0.485366 -0.848947  0.181907 -0.040826  \n",
       "4  0.122542  0.693578 -0.615971 -0.848164  0.185124 -0.037080  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7767, 561)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3162, 561)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the training data into random forest classifier\n",
    "rf_classifier.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.9067046173308033\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Score: {}\".format(rf_classifier.score(X_train, y_train)))\n",
    "print(\"Testing Data Score: {}\".format(rf_classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [5 5 5 5 5 5 5 5 5 5]\n",
      "First 10 Actual labels:    0\n",
      "0  5\n",
      "1  5\n",
      "2  5\n",
      "3  5\n",
      "4  5\n",
      "5  5\n",
      "6  5\n",
      "7  5\n",
      "8  5\n",
      "9  5\n"
     ]
    }
   ],
   "source": [
    "predictions = rf_classifier.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.97      0.92       496\n",
      "           2       0.89      0.89      0.89       471\n",
      "           3       0.96      0.86      0.91       420\n",
      "           4       0.89      0.87      0.88       508\n",
      "           5       0.88      0.91      0.90       556\n",
      "           6       1.00      1.00      1.00       545\n",
      "           7       0.74      0.74      0.74        23\n",
      "           8       0.91      1.00      0.95        10\n",
      "           9       0.70      0.88      0.78        32\n",
      "          10       0.67      0.64      0.65        25\n",
      "          11       0.79      0.61      0.69        49\n",
      "          12       0.64      0.52      0.57        27\n",
      "\n",
      "    accuracy                           0.91      3162\n",
      "   macro avg       0.83      0.82      0.82      3162\n",
      "weighted avg       0.91      0.91      0.91      3162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification metrics\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "target_names = np.arange(1,13)\n",
    "\n",
    "print(classification_report(y_test.values, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.84      0.83       496\n",
      "           2       0.78      0.94      0.85       471\n",
      "           3       0.83      0.61      0.70       420\n",
      "           4       0.55      0.90      0.68       508\n",
      "           5       0.86      0.40      0.54       556\n",
      "           6       1.00      0.86      0.92       545\n",
      "           7       0.27      0.65      0.38        23\n",
      "           8       0.53      0.90      0.67        10\n",
      "           9       0.52      0.75      0.62        32\n",
      "          10       0.41      0.84      0.55        25\n",
      "          11       0.63      0.55      0.59        49\n",
      "          12       0.53      0.30      0.38        27\n",
      "\n",
      "    accuracy                           0.75      3162\n",
      "   macro avg       0.64      0.71      0.64      3162\n",
      "weighted avg       0.79      0.75      0.74      3162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.57      0.65       496\n",
      "           2       0.82      0.55      0.66       471\n",
      "           3       0.51      0.89      0.65       420\n",
      "           4       0.81      0.72      0.77       508\n",
      "           5       0.79      0.81      0.80       556\n",
      "           6       1.00      0.96      0.98       545\n",
      "           7       0.41      0.61      0.49        23\n",
      "           8       0.82      0.90      0.86        10\n",
      "           9       0.44      0.56      0.49        32\n",
      "          10       0.32      0.48      0.39        25\n",
      "          11       0.60      0.57      0.58        49\n",
      "          12       0.56      0.67      0.61        27\n",
      "\n",
      "    accuracy                           0.75      3162\n",
      "   macro avg       0.65      0.69      0.66      3162\n",
      "weighted avg       0.78      0.75      0.75      3162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "#Transform data from [-1, 1] to [0, 1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_scaled, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.01      0.01       496\n",
      "           2       0.02      0.00      0.00       471\n",
      "           3       0.28      1.00      0.44       420\n",
      "           4       1.00      0.00      0.01       508\n",
      "           5       0.65      0.98      0.78       556\n",
      "           6       0.71      1.00      0.83       545\n",
      "           7       0.00      0.00      0.00        23\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.00      0.00      0.00        32\n",
      "          10       0.00      0.00      0.00        25\n",
      "          11       0.00      0.00      0.00        49\n",
      "          12       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.48      3162\n",
      "   macro avg       0.25      0.25      0.17      3162\n",
      "weighted avg       0.50      0.48      0.34      3162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Complement Naive Bayes\n",
    "#Transform data from [-1, 1] to [0, 1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train_scaled, y_train)\n",
    "y_pred_cnb = cnb.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.84      0.82       496\n",
      "           2       0.77      0.93      0.84       471\n",
      "           3       0.84      0.60      0.70       420\n",
      "           4       0.87      0.74      0.80       508\n",
      "           5       0.80      0.87      0.83       556\n",
      "           6       1.00      0.98      0.99       545\n",
      "           7       0.41      0.83      0.55        23\n",
      "           8       0.62      0.80      0.70        10\n",
      "           9       0.51      0.78      0.62        32\n",
      "          10       0.58      0.72      0.64        25\n",
      "          11       0.62      0.37      0.46        49\n",
      "          12       0.67      0.59      0.63        27\n",
      "\n",
      "    accuracy                           0.82      3162\n",
      "   macro avg       0.71      0.75      0.71      3162\n",
      "weighted avg       0.83      0.82      0.82      3162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli Naive Bayes\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_bnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a numpy array for Keras\n",
    "X_train_arr = X_train.values\n",
    "X_test_arr = X_test.values\n",
    "\n",
    "# One-hot encoding the labels\n",
    "y_train_arr =  to_categorical(y_train)\n",
    "y_test_arr = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# add the first layer of training data\n",
    "model.add(Dense(100, activation=\"relu\", input_dim = X_train_arr.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Adding a dropout layer to prevent overfitting\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding second hidden layer\n",
    "model.add(Dense(100, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding third hidden layer\n",
    "# model.add(Dense(100, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "model.add(Dense(y_train_arr.shape[1], activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# Using categorical_crossentropy for the loss function, adam optimizer and accuracy metric\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8964 - acc: 0.6401\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4497 - acc: 0.8199\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3552 - acc: 0.8593\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2892 - acc: 0.8857\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2625 - acc: 0.8971\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2423 - acc: 0.9007\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2133 - acc: 0.9127\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2342 - acc: 0.9051\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2143 - acc: 0.9139\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1912 - acc: 0.9191\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.1987 - acc: 0.9185\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2047 - acc: 0.9226\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1882 - acc: 0.9209\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1688 - acc: 0.9316\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1785 - acc: 0.9287\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1737 - acc: 0.9284\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1641 - acc: 0.9360\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1693 - acc: 0.9333\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.1653 - acc: 0.9340\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.1686 - acc: 0.9289\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.1629 - acc: 0.9359\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.1541 - acc: 0.9354\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.1637 - acc: 0.9347\n",
      "Epoch 24/100\n",
      " - 2s - loss: 0.1358 - acc: 0.9439\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.1458 - acc: 0.9370\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.1359 - acc: 0.9445\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.1417 - acc: 0.9428\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1343 - acc: 0.9444\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1324 - acc: 0.9458\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.1336 - acc: 0.9463\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.1362 - acc: 0.9448\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.1317 - acc: 0.9459\n",
      "Epoch 33/100\n",
      " - 2s - loss: 0.1234 - acc: 0.9488\n",
      "Epoch 34/100\n",
      " - 2s - loss: 0.1220 - acc: 0.9513\n",
      "Epoch 35/100\n",
      " - 2s - loss: 0.1314 - acc: 0.9466\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1328 - acc: 0.9454\n",
      "Epoch 37/100\n",
      " - 2s - loss: 0.1135 - acc: 0.9537\n",
      "Epoch 38/100\n",
      " - 2s - loss: 0.1289 - acc: 0.9493\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.1369 - acc: 0.9440\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.1407 - acc: 0.9396\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.1357 - acc: 0.9441\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.1292 - acc: 0.9476\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.1305 - acc: 0.9491\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.1332 - acc: 0.9455\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.1244 - acc: 0.9497\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.1256 - acc: 0.9500\n",
      "Epoch 47/100\n",
      " - 2s - loss: 0.1170 - acc: 0.9534\n",
      "Epoch 48/100\n",
      " - 2s - loss: 0.1208 - acc: 0.9517\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.1267 - acc: 0.9450\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.1275 - acc: 0.9484\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.1236 - acc: 0.9513\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.1218 - acc: 0.9533\n",
      "Epoch 53/100\n",
      " - 2s - loss: 0.1094 - acc: 0.9576\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.1158 - acc: 0.9551\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.1091 - acc: 0.9548\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.1381 - acc: 0.9440\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.1042 - acc: 0.9584\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0977 - acc: 0.9633\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.1093 - acc: 0.9539\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.1105 - acc: 0.9543\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.1186 - acc: 0.9575\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.1131 - acc: 0.9552\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.1168 - acc: 0.9518\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.1043 - acc: 0.9566\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.1268 - acc: 0.9506\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.0962 - acc: 0.9615\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.1062 - acc: 0.9565\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.1087 - acc: 0.9543\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.1236 - acc: 0.9484\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.1163 - acc: 0.9526\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.1162 - acc: 0.9526\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.1058 - acc: 0.9561\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.0970 - acc: 0.9623\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.0927 - acc: 0.9634\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0958 - acc: 0.9610\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.0914 - acc: 0.9640\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.1017 - acc: 0.9606\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.0984 - acc: 0.9614\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.0948 - acc: 0.9610\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.0972 - acc: 0.9618\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.0946 - acc: 0.9621\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0986 - acc: 0.9587\n",
      "Epoch 83/100\n",
      " - 2s - loss: 0.1038 - acc: 0.9579\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.0871 - acc: 0.9659\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.0929 - acc: 0.9629\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.0880 - acc: 0.9658\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.0933 - acc: 0.9597\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.0980 - acc: 0.9611\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.0893 - acc: 0.9660\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.1074 - acc: 0.9584\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.1079 - acc: 0.9574\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.0998 - acc: 0.9629\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.1044 - acc: 0.9611\n",
      "Epoch 94/100\n",
      " - 2s - loss: 0.0906 - acc: 0.9624\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.0948 - acc: 0.9629\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.0923 - acc: 0.9645\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.0824 - acc: 0.9664\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1004 - acc: 0.9628\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.0913 - acc: 0.9643\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.0814 - acc: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4a552dd8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_arr, y_train_arr, epochs = 100, shuffle = True, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(\"deep_learning_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"deep_learning_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"deep_learning_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.24422230586862947, Accuracy: 0.9307400584220886\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model_loss, model_accuracy = model.evaluate(X_test_arr, y_test_arr, verbose =3)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which row you want to start from?(Range 1-3162) \n",
      "100\n",
      "Which row you want it to end?\n",
      "200\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: WALKING_UPSTAIRS\t\t   PREDICTED: WALKING_UPSTAIRS\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: SITTING\t\t   PREDICTED: SITTING\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: WALKING_DOWNSTAIRS\t\t   PREDICTED: WALKING_DOWNSTAIRS\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: SIT_TO_STAND\t\t   PREDICTED: SIT_TO_STAND\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: STANDING\t\t   PREDICTED: STANDING\n",
      " OBSERVED: SIT_TO_LIE\t\t   PREDICTED: SIT_TO_LIE\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n",
      " OBSERVED: LAYING\t\t   PREDICTED: LAYING\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to specify the row numbers you want to test/compare\n",
    "\n",
    "# Predict the class of given data\n",
    "\n",
    "def predictor(data):\n",
    "    return model.predict_classes(data)\n",
    "\n",
    "# Decoding the label integer into its actual class name\n",
    "def decoder(num):\n",
    "    return y_labels[0][int(num)].strip().split()[1]\n",
    "\n",
    "def compare(row_num):\n",
    "    test_data = np.expand_dims(X_test_arr[row_num], axis = 0)\n",
    "    print (f\" OBSERVED: {decoder(y_test.iloc[row_num,0])}\\t\\t   PREDICTED: {decoder(predictor(test_data))}\")\n",
    "\n",
    "\n",
    "begin = int(input(\"Which row you want to start from?(Range 1-3162) \\n\"))-1\n",
    "end = int(input(\"Which row you want it to end?\\n\"))\n",
    "for i in range(begin, end):\n",
    "    compare(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
